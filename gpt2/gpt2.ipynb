{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda3\\envs\\tensorflow_GPU\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook that allows you to train your own GPT2 model. The networks uses the pretrained 124M parameters model, and can quickly easily fit on a 6GB GPU. \n",
    "\n",
    "### The model takes ~5.8GB to store the parameters so a small batch size is required (A size of 4 seems best but you could change this). \n",
    "\n",
    "## Another option is to use the CPU but that would be quite slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "if not os.path.exists(\"models/124M\"):\n",
    "    gpt2.download_gpt2(\"124M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 03 17:00:27 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 456.71       Driver Version: 456.71       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 106... WDDM  | 00000000:25:00.0  On |                  N/A |\n",
      "|  0%   57C    P0    27W / 200W |    849MiB /  6144MiB |      5%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1860    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      1992    C+G   ...n64\\EpicGamesLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A      2316    C+G   ...TeamViewer\\TeamViewer.exe    N/A      |\n",
      "|    0   N/A  N/A      5148    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      8236    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      8260    C+G   ...aming\\Spotify\\Spotify.exe    N/A      |\n",
      "|    0   N/A  N/A      8628    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      8748    C+G   ...b3d8bbwe\\WinStore.App.exe    N/A      |\n",
      "|    0   N/A  N/A      9200    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12128    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     13480    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     14684    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     15364    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     16420    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     16700    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     16836    C+G   ...s\\Win64\\EpicWebHelper.exe    N/A      |\n",
      "|    0   N/A  N/A     16860    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../hi_all_text.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt2.reset_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0203 17:01:02.105000 12056 deprecation.py:323] From D:\\GitHub\\HelloInternet_old\\gpt-2-simple\\gpt_2_simple\\src\\sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0203 17:01:18.024088 12056 deprecation.py:323] From D:\\Miniconda3\\envs\\tensorflow_GPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/124M\\model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:20<00:00, 20.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 3423010 tokens\n",
      "Training...\n",
      "======== SAMPLE 1 ========\n",
      " lux.\n",
      "[Pg 80]\n",
      "[Pg 81]Well, yes, I know this in case it's my second time reading this. I've come upon it as I've come across an article about the French philosopher in 1887.\n",
      "[Pg 82]Of course that was he's famous. It was published by a bookseller in France. And there's this very interesting article that he wrote about the bookseller in 1887 called What is a man? It's about this great Frenchman. He's a philosopher in England and he's a philosopher by his bookseller. So in 1887, when it became fashionable in Britain, he was writing as a bookseller, but apparently he didn't go and do his thing, and was quite a bit of a problem in British society. Like he wrote about himself. So he found another, another way of looking at it. And it was in 1889, when it was fashionable, that he made a book of it and put out\n",
      "\n",
      "======== SAMPLE 1 ========\n",
      " was in the wrong category. If you were thinking about my family of friends who are going to get married in the future, I think maybe it was my daughter that was getting married, but I have always just been saying, Oh, that's just my daughter. How are you going to take care of her? It's not like I'm going to ask anyone. It's my job, I'm going to not be doing anything. Because I know, like, I know I'm not going to talk. I know, I'm going to be my own person and I'm not going to talk for anyone.\n",
      "[Grey] Yeah, I guess you wouldn't be worried about talking? Okay, I would be worried, yeah. But you wouldn't be worried about, like, the little girl who's going to start telling you her story about getting married or I, in fact, I am, I'm not doing anything. I am doing a podcast for a podcast.\n",
      "[Br\n",
      "\n",
      "[25 | 94.54] loss=3.15 avg=3.15\n",
      "======== SAMPLE 1 ========\n",
      " wrong is that in terms of the quality of the game the game is terrible. On the other hand if I were sitting there in a position where the computer wasn't running all night I would just feel like no, no, no, it's like they're gonna be at the very, very end of a day. Like the game itself is horrible, but it's not because it's like, man, because it's, it's great. I just don't know how bad this is. And if you do get to play the game, like that was like, all right. Like I love playing that but it's not the game, or even the game at all. It's just like like I feel like, well, this is, man, this is exactly what we want to be. Like that's what this is is not the game. This is what we want to be. That's why we've made this game. I don't know why we've made this one.\n",
      "\n",
      "======== SAMPLE 1 ========\n",
      " It of course, they're still there and there's like that. You know?\n",
      "[Brady] Are they or are they you get really angry about.\n",
      "[Grey] Yeah, that's a very big question. Because there is this huge problem that the people in that community, that's the way they've taken this. I think that the solution is to have more people do it. You know, the only way would be to have more people and then to have an infinite number of people. Maybe you don't necessarily like that idea, right, but I do not think that way does that.\n",
      "[Brady] Right?\n",
      "[Grey] Do you know how many kids do children want to do things? I don't know. Do you think that there is more to do? Yeah, and that's one thing the solution is to make people do things. And that seems to me like the only way to do it is to have more of them Do it,\n",
      "\n",
      "\n",
      "[50 | 180.26] loss=3.20 avg=3.17\n",
      "Saving checkpoint/hi-machina/model-50\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Restore model from 'fresh' if the model is new, or 'latest' if you want to use a model that has been saved (checkpoint). To change, simply\n",
    "    uncomment the one you wish to you and comment out the other using #\n",
    "    \n",
    "    Models are saved in the checkpoint folder, and contains all the information about the model.\n",
    "    \n",
    "    You may need to restart the session, perhaps if you continue training. In this case simply use the code above \n",
    "    \n",
    "    >> gpt2.reset_session(sess)\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              dataset=file_name,\n",
    "              model_name='124M',\n",
    "              steps=50,\n",
    "              restore_from='fresh',\n",
    "              #restore_from='latest',\n",
    "              run_name='hi-machina',\n",
    "              print_every=25,\n",
    "              sample_every=10,\n",
    "              overwrite=True,\n",
    "              save_every=50,\n",
    "              batch_size=4,\n",
    "              use_memory_saving_gradients=True,\n",
    "              sample_length=200,\n",
    "              accumulate_gradients=1\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can play about with the temperature, which effects the creativity of the predictions (The example below is from a model that trained for 10000 steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"[Grey] Brady no more plane crash corner\"\n",
    "temperature = 0.7\n",
    "\n",
    "gpt2.generate_to_file(sess, run_name='hi-machina', prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "with open(\"gpt_2_gen_texts.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if len(line.strip()) > 0:\n",
    "            text.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Grey] Brady no more plane crash corner. Yeah,\n",
      "[Brady] yeah. But But yeah, we've got plane crash corner on the internet.\n",
      "[Grey] It's plane crash corner, right?\n",
      "[Brady] Well, I mean, if you say something plane crash corner, you go. Okay, well,\n",
      "[Grey] I went on the internet to see the website and I got that Brady's paper cut not that I've got not that I've got paper cuts internet\n",
      "[Brady] I have gone on the internet. And I got the link to this article about plane crash corner. I'm looking at it straight away. And I'm like, okay, all right, but it's not plane crash corner. I went looking for it. And I haven't come across it. I went looking for it on the internet. But no one has seen it. And I was like, No, no one has. But somebody has.\n",
      "[Grey] This is why I was like a little bit terrified when the article came out. Because I don't know who this is. This is just this is what this is. This is the internet. This is what the internet is. It's the world's premier source of news. It's the source of all of the internet's news. So I was like, Okay, I'm gonna warn you. I'm going to warn you. I'm not going to tell you that. But I did pull out my iPhone and saw this article that you'd probably seen before. It's about this incident that ended up getting me into a plane. And it's about this incident that took the life of this pilot, who was doing the finding of the plane. And he says he did not panic or call for help or apologize or explain what was going on. Instead, he says he crashed the plane as the search and rescue efforts go on. And it's just like this, this amazing, amazing thing. And I just came away from this article thinking, wow, I'm glad people are aware of this. Even though I don't know nothing about this, and I don't know what happened, I was just so outraged by this thing that I was like, I don't know, I just I don't want to know who it was. I don't want to know what caused or the way it happened. And I was like, wow, it was amazing. I can't believe that you know, this is the first time I've ever heard about a plane crash. So I'm like, Oh, I can't believe it. And I was like, What the heck are you talking about? And I was like, I'm just reading this article. And it's like, oh, it's totally amazing.\n",
      "[Brady] I don't know. I just find it very strange. And I don't know if you're out of the plane, but I mean, I don't even know what happened. Like, I don't know, I'm perfectly okay with it. There's no like, problems. No, no problems at all.\n",
      "[Grey] I'm a little bit worried about this because when I saw this article, and I saw that it was about plane crash corner, I was like, oh my goodness, what is this? It's about plane crash corner?\n",
      "[Brady] Well, I mean, this is this is where we are now. Like, we're more aware of it, because we just got this big story that got me into a few other websites about a plane crash that happened a few weeks ago. But I mean, this is a story of the very, very, very early days of our careers. So it's like, I don't know, I don't know how things work in advertising. I guess I don't know what happened. But I don't know. I'm not sure how it works. Like, I don't know anything about it. I don't know. I think it's probably a bit of a mystery to me how it works. And I don't know what caused it, or how long it's been a mystery to me. I don't know. I just don't know. What's the point of mystery to me? Why is a mystery?\n",
      "[Grey] I know.\n",
      "[Brady] It's not a mystery. What's the point of mystery? Why is it a mystery is to be a bit suspicious of what's going on? Because it's like, you know, it's like a bit of a mystery. Okay, why is this mystery? I mean, it's not like, I think, you know, it's not like, I've seen a couple of interesting things in it, but this is just like, it's not like a mystery. What's going on? They're not like, Oh, like, you know, you know, I'm not a big fan of the new\n"
     ]
    }
   ],
   "source": [
    "for line in text:\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
