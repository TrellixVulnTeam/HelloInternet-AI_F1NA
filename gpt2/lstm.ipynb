{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "numeric-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torchtext\n",
    "\n",
    "from lstm import HILanguageModelDataset, LanguageModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-voice",
   "metadata": {},
   "source": [
    "# LSTM-Based Neural Language Model\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "### This model is trained from scratch and is much smaller and slower to train that the GPT2 model. Nonetheless it requires much less resources to train. During training, it should consume at most 3GB from GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seventh-creator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "D:\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/hi_all_text.txt\"\n",
    "\n",
    "TEXT = torchtext.data.Field()\n",
    "nlm_data = HILanguageModelDataset(path=path, text_field=TEXT)\n",
    "\n",
    "train, val, test = nlm_data.split(split_ratio=[0.9, 0.05, 0.05], text_field=TEXT)\n",
    "\n",
    "TEXT.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "successful-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BPTTIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iter, val_iter, test_iter = torchtext.data.BPTTIterator.splits((train, val, test), batch_size=20, bptt_len=35, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "announced-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModel(650, len(TEXT.vocab.itos), 2, 0.05, 0.5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continental-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_states():\n",
    "    return (torch.autograd.Variable(torch.zeros(2, 20, 650)).cuda(), \n",
    "                    torch.autograd.Variable(torch.zeros(2, 20, 650)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fancy-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.0\n",
    "epochs = 39\n",
    "decay_rate = 0.8\n",
    "max_epochs = 6\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss(reduction='sum').cuda()\n",
    "op = torch.optim.SGD(model.parameters(), lr=1.0)\n",
    "\n",
    "def set_lr(epoch):\n",
    "    lr_decay = decay_rate ** max(epoch + 1 - max_epochs, 0.0)\n",
    "    return lr_decay\n",
    "\n",
    "lr_schedule = torch.optim.lr_scheduler.LambdaLR(op, set_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, timeit \n",
    "\n",
    "epochs = 39\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch:', epoch)\n",
    "    lr_schedule.step()\n",
    "\n",
    "    # run training iteration\n",
    "    states = zero_states()\n",
    "    losses = 0\n",
    "    for step, batch in enumerate(train_iter):\n",
    "        x, y = batch.text, batch.target\n",
    "        op.zero_grad()\n",
    "        pred, states = model(x.cuda(), states, train=True)\n",
    "        y_cuda = y.cuda()\n",
    "        batch_loss = loss(pred.view(-1, len(TEXT.vocab.itos)), y_cuda.view(-1))\n",
    "\n",
    "        losses += (batch_loss.cpu().detach() / (20*35))\n",
    "\n",
    "        batch_loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        op.step()\n",
    "        sys.stdout.write('\\r' + 'Training: ' + str(epoch) + '   Progress: ' + str(step) + \n",
    "                           '/' + str(len(train_iter)) + '   Loss: ' + str(np.around(losses/ (step+1), 3)) +\n",
    "                        ' Perplexity: ' + str(np.exp(np.around(losses/ (step+1), 3)))\n",
    "                        )\n",
    "    print('')\n",
    "\n",
    "    # run validation iteration\n",
    "    states = zero_states()\n",
    "    losses = 0\n",
    "    for step, batch in enumerate(val_iter):\n",
    "        x, y = batch.text, batch.target.view(-1)\n",
    "        pred, states = model(x.cuda(), states, train=False)\n",
    "        y_cuda = y.cuda()\n",
    "        batch_loss = loss(pred, y_cuda)\n",
    "\n",
    "        losses += (batch_loss.cpu().detach() / (20*35))\n",
    "\n",
    "        sys.stdout.write('\\r' + 'Validation:' + str(epoch) + '   Progress: ' + str(step) + \n",
    "                           '/' + str(len(val_iter)) + '   Loss: ' + str(np.around(losses/ (step+1), 3)) +\n",
    "                         ' Perplexity: ' + str(np.exp(np.around(losses/ (step+1), 3)))\n",
    "                        )\n",
    "\n",
    "    print('')\n",
    "    print('')\n",
    "print('')\n",
    "print(timeit.default_timer() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
